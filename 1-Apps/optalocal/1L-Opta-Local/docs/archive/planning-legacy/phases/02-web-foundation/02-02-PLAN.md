---
phase: 02-web-foundation
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - 1-Apps/1L-Opta-Local/web/src/hooks/useModels.ts
  - 1-Apps/1L-Opta-Local/web/src/components/chat/ModelPicker.tsx
  - 1-Apps/1L-Opta-Local/web/src/lib/chat-store.ts
  - 1-Apps/1L-Opta-Local/web/src/app/chat/page.tsx
  - 1-Apps/1L-Opta-Local/web/src/components/chat/ChatContainer.tsx
autonomous: true
status: review
---

<objective>
Add model selection and chat history persistence to the streaming chat UI.

Purpose: Complete the chat experience with the ability to select loaded models and persist conversations locally via IndexedDB, enabling users to return to previous chats.
Output: A model picker dropdown in the chat interface and automatic chat history persistence using idb-keyval.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-web-foundation/02-RESEARCH.md
@.planning/phases/02-web-foundation/02-01-SUMMARY.md

# Source files from Plan 02-01:
@1-Apps/1L-Opta-Local/web/src/hooks/useChatStream.ts
@1-Apps/1L-Opta-Local/web/src/components/chat/ChatContainer.tsx
@1-Apps/1L-Opta-Local/web/src/app/chat/page.tsx
@1-Apps/1L-Opta-Local/web/src/lib/lmx-client.ts
@1-Apps/1L-Opta-Local/web/src/lib/connection.ts
@1-Apps/1L-Opta-Local/web/src/types/lmx.ts

# Design system:
@1-Apps/1L-Opta-Local/web/CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create model list hook and model picker component</name>
  <files>
    1-Apps/1L-Opta-Local/web/src/hooks/useModels.ts,
    1-Apps/1L-Opta-Local/web/src/components/chat/ModelPicker.tsx
  </files>
  <action>
    1. Create `src/hooks/useModels.ts` ('use client'):
       - Uses SWR to fetch loaded models from LMXClient.getModels()
       - Refresh interval: 10 seconds (models may be loaded/unloaded)
       - Returns { models: LoadedModel[], isLoading, error, refresh }
       - Handles connection errors gracefully (empty array when server unreachable)

    2. Create `src/components/chat/ModelPicker.tsx` ('use client'):
       - Uses @radix-ui/react-select for the dropdown — NOT native HTML select
       - Glass-subtle trigger button showing selected model name (truncated if long)
       - Each option shows: model name, quantization badge, context length, VRAM usage
       - Use @radix-ui/react-tooltip on each option for full model path on hover
       - Empty state: "No models loaded" with link to dashboard
       - Loading state: skeleton placeholder
       - Props: { selectedModel: string, onModelChange: (model: string) => void, models: LoadedModel[] }
       - Style with Opta glass design: glass backgrounds, violet accent for selected, cn() for classes
  </action>
  <verify>pnpm run build passes; ModelPicker renders with Radix Select; useModels fetches from LMX</verify>
  <done>Model picker shows loaded models with metadata; useModels hook polls LMX every 10s</done>
</task>

<task type="auto">
  <name>Task 2: Create chat history persistence and integrate model picker</name>
  <files>
    1-Apps/1L-Opta-Local/web/src/lib/chat-store.ts,
    1-Apps/1L-Opta-Local/web/src/app/chat/page.tsx,
    1-Apps/1L-Opta-Local/web/src/components/chat/ChatContainer.tsx
  </files>
  <action>
    1. Create `src/lib/chat-store.ts`:
       - Uses idb-keyval for IndexedDB key-value storage (NOT localStorage — chat histories are too large)
       - Interface ChatSession: { id: string, title: string, model: string, messages: ChatMessage[], created_at: string, updated_at: string }
       - saveChatSession(session): persist to IndexedDB
       - getChatSession(id): retrieve by ID
       - listChatSessions(): list all sessions sorted by updated_at desc (returns summary without full messages)
       - deleteChatSession(id): remove
       - Auto-generate title from first user message (first 60 chars)
       - These are LOCAL web sessions (not CLI sessions — Phase 5 handles CLI session resume)

    2. Update ChatContainer to:
       - Accept modelPicker slot/prop or integrate ModelPicker directly
       - Auto-save chat to IndexedDB after each assistant response completes (not during streaming)
       - Generate session ID with crypto.randomUUID() on first message
       - Support loading existing session by ID (for "recent chats" sidebar later)

    3. Update `/chat` page to:
       - Integrate useModels hook
       - Pass selected model to ChatContainer
       - Add ModelPicker to the chat header area
       - Default to first loaded model if none selected
       - Add simple nav link back to dashboard (Lucide ArrowLeft icon)
  </action>
  <verify>pnpm run build passes; model picker appears in chat header; sending a message persists the session to IndexedDB (verify in browser DevTools > Application > IndexedDB)</verify>
  <done>Model picker integrated in chat header; chat sessions auto-save to IndexedDB after each response; sessions can be loaded by ID</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `cd 1-Apps/1L-Opta-Local/web && pnpm run build` succeeds without errors
- [ ] Model picker shows loaded models with metadata (quantization, VRAM, context length)
- [ ] Selecting a model changes the model used for chat completions
- [ ] Chat sessions persist to IndexedDB automatically
- [ ] Page refresh preserves the last session
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Model picker renders with Radix Select styling
- Chat sessions survive page refresh via IndexedDB
- Complete "chat with your local AI" experience functional
</success_criteria>

<output>
After completion, create `.planning/phases/02-web-foundation/02-02-SUMMARY.md`
</output>
