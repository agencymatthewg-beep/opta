---
phase: 01-web-project-setup
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - 1-Apps/1L-Opta-Local/web/src/types/lmx.ts
  - 1-Apps/1L-Opta-Local/web/src/lib/lmx-client.ts
  - 1-Apps/1L-Opta-Local/web/src/lib/storage.ts
  - 1-Apps/1L-Opta-Local/web/src/lib/connection.ts
autonomous: true
status: review
---

<objective>
Create typed LMX API client library and encrypted connection settings management.

Purpose: Provide the typed API layer and secure credential storage that all future phases (streaming chat, dashboard, model management) depend on. This is the bridge between the browser and the Mac Studio LMX server.
Output: TypeScript LMX client with full SHARED.md API coverage, encrypted admin key storage via Web Crypto API, and connection settings persistence.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-web-project-setup/01-RESEARCH.md
@.planning/phases/01-web-project-setup/01-01-SUMMARY.md

# API contracts and data models:
@1-Apps/1L-Opta-Local/SHARED.md

# Platform coding standards:
@1-Apps/1L-Opta-Local/web/CLAUDE.md

# Project scaffold (created by Plan 01):
@1-Apps/1L-Opta-Local/web/tsconfig.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TypeScript types and LMX API client</name>
  <files>
    1-Apps/1L-Opta-Local/web/src/types/lmx.ts,
    1-Apps/1L-Opta-Local/web/src/lib/lmx-client.ts
  </files>
  <action>
    **types/lmx.ts:** Define all TypeScript interfaces from SHARED.md API contracts:
    - ServerStatus: { server_name, version, uptime_seconds, gpu: { name, vram_total_gb, vram_used_gb, vram_free_gb, utilization_percent }, loaded_models: LoadedModel[], active_requests }
    - LoadedModel: { id, object, created, owned_by, max_context_length, quantization }
    - ChatMessage: { role: 'system' | 'user' | 'assistant', content: string }
    - ChatCompletionRequest: { model, messages: ChatMessage[], stream?: boolean, temperature?: number, max_tokens?: number, top_p?: number }
    - ChatCompletionResponse: { id, object, created, model, choices: { index, message: ChatMessage, finish_reason }[], usage: { prompt_tokens, completion_tokens, total_tokens } }
    - ChatCompletionChunk: { id, object, created, model, choices: { index, delta: { role?, content? }, finish_reason? }[] }
    - Session: { id, model, messages: ChatMessage[], created_at, updated_at, title? }
    - LMXError class extending Error with status and body fields
    - ModelLoadRequest: { model_path: string, quantization?: string }

    Export all types. Use strict TypeScript — no `any`, all fields typed.

    **lib/lmx-client.ts:** Create LMXClient class using native fetch (no axios — per CLAUDE.md):
    - Constructor takes baseUrl and adminKey
    - Private headers() method returning Content-Type + X-Admin-Key
    - Private async request<T>(path, options?) with error handling that throws LMXError on non-2xx
    - getStatus(): Promise<ServerStatus> — GET /admin/status
    - getModels(): Promise<{ data: LoadedModel[] }> — GET /v1/models
    - loadModel(req: ModelLoadRequest): Promise<LoadedModel> — POST /admin/models/load
    - unloadModel(modelId: string): Promise<void> — POST /admin/models/unload
    - chatCompletion(req: ChatCompletionRequest): Promise<ChatCompletionResponse> — POST /v1/chat/completions (non-streaming)
    - streamChat(model, messages, options?): AsyncGenerator<string> — POST /v1/chat/completions with stream:true. Parse SSE lines (data: {...}), yield delta.content, handle [DONE] sentinel. Use ReadableStream reader + TextDecoder.
    - healthCheck(): Promise<boolean> — GET /admin/status, returns true/false (swallows errors)

    Use async generators for streaming (not callbacks). Include proper error types. Do NOT use EventSource for chat streaming — fetch with ReadableStream is more flexible and supports custom headers.
  </action>
  <verify>
    cd 1-Apps/1L-Opta-Local/web && npx tsc --noEmit
    (TypeScript compiles with zero errors — all types consistent, all methods properly typed)
  </verify>
  <done>
    - types/lmx.ts exports all SHARED.md data models as TypeScript interfaces
    - LMXClient has methods for all core API endpoints (status, models, chat, load/unload)
    - streamChat() uses async generator with ReadableStream (not EventSource)
    - LMXError class provides structured error info (status, body)
    - healthCheck() returns boolean without throwing
    - Zero TypeScript errors
    - No `any` types used
  </done>
</task>

<task type="auto">
  <name>Task 2: Create encrypted connection settings with Web Crypto API</name>
  <files>
    1-Apps/1L-Opta-Local/web/src/lib/storage.ts,
    1-Apps/1L-Opta-Local/web/src/lib/connection.ts
  </files>
  <action>
    **lib/storage.ts:** Encrypted localStorage wrapper using Web Crypto API (mandatory per web/CLAUDE.md — admin keys must never be stored in plaintext):
    - encryptValue(value: string): Promise<string> — AES-GCM encrypt with random IV, derive key from a stable seed (use window.location.origin as salt + a fixed app identifier via PBKDF2). Return base64-encoded JSON of { iv, ciphertext }.
    - decryptValue(encrypted: string): Promise<string> — Parse base64, decrypt with same derived key.
    - setSecure(key: string, value: string): Promise<void> — Encrypt then store in localStorage.
    - getSecure(key: string): Promise<string | null> — Read from localStorage, decrypt. Return null if not found or decryption fails.
    - removeSecure(key: string): void — Remove from localStorage.

    NOTE: This is defense-in-depth, not perfect security. XSS can still access the key through the running app, but it prevents casual exposure in devtools/localStorage inspection. The real protection is same-origin policy + no external scripts.

    **lib/connection.ts:** Connection settings management:
    - ConnectionSettings type: { host: string, port: number, adminKey: string, useTunnel: boolean, tunnelUrl: string }
    - DEFAULT_SETTINGS constant: { host: '192.168.188.11', port: 1234, adminKey: '', useTunnel: false, tunnelUrl: '' }
    - getConnectionSettings(): Promise<ConnectionSettings> — Read from storage (adminKey encrypted, rest in plain localStorage). Merge with defaults for missing fields.
    - saveConnectionSettings(settings: ConnectionSettings): Promise<void> — Save with adminKey encrypted, rest in plain localStorage.
    - getBaseUrl(settings: ConnectionSettings): string — Returns `http://${host}:${port}` or tunnelUrl based on useTunnel flag.
    - createClient(settings: ConnectionSettings): LMXClient — Factory that creates LMXClient with correct baseUrl and adminKey.

    Import LMXClient from ./lmx-client. All functions are async (Web Crypto is async).
  </action>
  <verify>
    cd 1-Apps/1L-Opta-Local/web && npx tsc --noEmit
    (TypeScript compiles with zero errors — storage and connection types align with LMXClient)
  </verify>
  <done>
    - storage.ts encrypts/decrypts values using Web Crypto API (AES-GCM)
    - Admin key is never stored as plaintext in localStorage
    - connection.ts provides typed ConnectionSettings with sensible defaults (192.168.188.11:1234)
    - createClient() factory produces a configured LMXClient instance
    - getBaseUrl() correctly switches between LAN and tunnel URLs
    - Zero TypeScript errors
    - No `any` types used
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `cd 1-Apps/1L-Opta-Local/web && npx tsc --noEmit` passes with zero errors
- [ ] `pnpm build` succeeds (confirms all imports resolve)
- [ ] types/lmx.ts exports all SHARED.md data models
- [ ] LMXClient covers: getStatus, getModels, loadModel, unloadModel, chatCompletion, streamChat, healthCheck
- [ ] storage.ts uses Web Crypto API (not plaintext localStorage)
- [ ] connection.ts default host is 192.168.188.11, port 1234
- [ ] No `any` types anywhere in new files
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- LMX API client fully typed with all SHARED.md endpoints
- Streaming chat uses async generator pattern (not callbacks)
- Admin key encrypted in localStorage via Web Crypto API
- Connection settings persist across sessions with sensible defaults
- LMXClient factory creates properly configured instances
</success_criteria>

<output>
After completion, create `.planning/phases/01-web-project-setup/01-02-SUMMARY.md`
</output>
