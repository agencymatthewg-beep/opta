<!DOCTYPE html>
<html lang="en" class="bg-[#09090b] text-[#fafafa] scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Opta Learn - LMX Masterclass (Comprehensive Edition)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://unpkg.com/lucide@latest"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: { sans: ['Sora', 'sans-serif'], mono: ['JetBrains Mono', 'monospace'] },
                    colors: {
                        void: '#09090b', surface: '#0c0c12', elevated: '#1a1a24',
                        amber: '#f59e0b', violet: '#a855f7', green: '#22c55e', blue: '#3b82f6',
                        text_primary: '#fafafa', text_secondary: '#a1a1aa', text_muted: '#52525b',
                        code_bg: '#0a0a0f', obsidian: 'rgba(5,3,10,0.8)'
                    }
                }
            }
        }
    </script>
    <style>
        .bg-grid-subtle { background-image: linear-gradient(to right, rgba(255,255,255,0.03) 1px, transparent 1px), linear-gradient(to bottom, rgba(255,255,255,0.03) 1px, transparent 1px); background-size: 48px 48px; }
        .obsidian { background: rgba(5,3,10,0.8); border: 1px solid rgba(255,255,255,0.05); backdrop-filter: blur(16px); border-radius: 16px; }
        .text-moonlight { background: linear-gradient(135deg, #ffffff 0%, #ffffff 50%, rgba(168,85,247,0.5) 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
        .callout { background: rgba(168,85,247,0.1); border-left: 3px solid #a855f7; }
        .glass-nav { background: rgba(12,12,18,0.8); backdrop-filter: blur(20px); border-bottom: 1px solid rgba(255,255,255,0.1); }
        .text-opta { color: #a855f7; -webkit-text-fill-color: #a855f7; display: inline; font-weight: inherit; }
        section { scroll-margin-top: 100px; }
        
        /* Inline Wikipedia-style App Links (Style 1: Colored Text + Dotted Underline) */
        .app-link { 
            font-weight: 500; 
            text-decoration: underline; 
            text-decoration-style: dotted; 
            text-underline-offset: 4px;
            transition: all 0.2s ease;
            cursor: pointer;
        }
        .app-link:hover { text-decoration-style: solid; text-decoration-thickness: 2px; }
        
        /* App-specific link colors */
        .link-cli { color: #22c55e; text-decoration-color: rgba(34,197,94,0.4); }
        .link-cli:hover { text-decoration-color: #22c55e; background: rgba(34,197,94,0.1); border-radius: 2px; }
        
        .link-accounts { color: #3b82f6; text-decoration-color: rgba(59,130,246,0.4); }
        .link-accounts:hover { text-decoration-color: #3b82f6; background: rgba(59,130,246,0.1); border-radius: 2px; }
        
        .link-init { color: #f59e0b; text-decoration-color: rgba(245,158,11,0.4); }
        .link-init:hover { text-decoration-color: #f59e0b; background: rgba(245,158,11,0.1); border-radius: 2px; }
        
        .link-dashboard { color: #a855f7; text-decoration-color: rgba(168,85,247,0.4); }
        .link-dashboard:hover { text-decoration-color: #a855f7; background: rgba(168,85,247,0.1); border-radius: 2px; }

        .toc-link { color: #a1a1aa; border-left: 2px solid transparent; transition: all 0.3s ease; display: block; padding-left: 16px; padding-top: 10px; padding-bottom: 10px; margin-left: -1px; }
        .toc-link:hover { color: #fafafa; background: rgba(255,255,255,0.02); }
        .toc-link.active { color: #fafafa; border-left-color: #a855f7; background: linear-gradient(90deg, rgba(168,85,247,0.1) 0%, transparent 100%); }
    </style>
</head>
<body class="bg-void min-h-screen relative overflow-x-hidden flex flex-col">
    <div class="fixed inset-0 bg-grid-subtle pointer-events-none -z-10"></div>
    
    <!-- Header -->
    <header class="fixed top-0 w-full z-50 glass-nav px-6 py-3 flex items-center justify-between">
        <div class="flex items-center gap-4 font-mono text-sm text-text_muted">
            <div class="flex items-center gap-2">
                <div class="w-2 h-2 rounded-full bg-violet shadow-[0_0_8px_rgba(168,85,247,0.8)]"></div>
                <span><span class="text-opta lowercase font-semibold">Opta</span> local</span> 
                <span>/</span> <span>learn</span> <span>/</span> <span class="text-violet">lmx</span>
            </div>
        </div>
        <div class="relative w-full max-w-md">
            <i data-lucide="search" class="absolute left-4 top-1/2 -translate-y-1/2 h-4 w-4 text-text_muted"></i>
            <input type="text" placeholder="Search guides..." class="w-full bg-[rgba(12,12,18,0.8)] border border-white/10 rounded-full pl-10 pr-4 py-2 text-sm text-text_primary focus:outline-none focus:border-violet/50" />
        </div>
        <div class="w-[150px]"></div>
    </header>

    <div class="flex flex-1 pt-[72px]">
        <!-- TOC Sidebar -->
        <aside class="w-72 fixed h-[calc(100vh-72px)] border-r border-white/10 p-8 flex flex-col gap-8 overflow-y-auto z-40 bg-void/80 backdrop-blur-md">
            <div class="flex flex-col gap-2">
                <span class="text-xs font-mono text-text_muted uppercase tracking-wider">Guide Navigation</span>
                <h2 class="text-lg font-semibold text-text_primary"><span class="text-opta">Opta</span> LMX Masterclass</h2>
            </div>
            <nav id="toc" class="flex flex-col text-sm font-sans font-medium border-l border-white/10">
                <a href="#overview" class="toc-link active" data-target="overview">1. Ecosystem Role</a>
                <a href="#competitors" class="toc-link" data-target="competitors">2. Competitive Landscape</a>
                <a href="#architecture" class="toc-link" data-target="architecture">3. Architecture & Memory</a>
                <a href="#capabilities" class="toc-link" data-target="capabilities">4. Core Capabilities</a>
                <a href="#features" class="toc-link" data-target="features">5. Full Feature Matrix</a>
                <a href="#workflows" class="toc-link" data-target="workflows">6. Integrated Workflows</a>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="flex-1 ml-72 p-12 lg:p-24 max-w-5xl flex flex-col gap-24 relative">
            
            <section id="overview" class="flex flex-col gap-6 pt-8">
                <div class="inline-flex items-center gap-2 w-max px-3 py-1 text-xs font-mono bg-violet/10 border border-violet/30 rounded text-violet uppercase tracking-wider">
                    Whole App Guide
                </div>
                <h1 class="text-6xl font-bold tracking-tight text-moonlight mb-2"><span class="text-opta">Opta</span> LMX Masterclass</h1>
                <p class="text-xl text-text_secondary max-w-3xl leading-relaxed">
                    The comprehensive, holistic guide to the Local Model eXecution engine.
                </p>
                <div class="text-text_secondary leading-relaxed text-lg mt-6 flex flex-col gap-6">
                    <p><span class="text-opta">Opta</span> LMX is the high-performance local inference engine acting as the beating heart of the stack. It runs entirely as a background daemon, removing the need for clunky graphical interfaces while providing enterprise-grade reliability for local large language models. While you might first deploy the platform using <a href="/guides/init" class="app-link link-init">Opta Init</a>, LMX is the silent powerhouse orchestrating the actual compute on your machine.</p>
                    <p>It acts as the invisible bridge. If you are typing autonomous agent commands into the <a href="/guides/cli" class="app-link link-cli">Opta CLI</a>, analyzing system health via the <a href="/guides/dashboard" class="app-link link-dashboard">Opta Local Dashboard</a>, or tracking historical sync states with <a href="/guides/accounts" class="app-link link-accounts">Opta Accounts</a>, they are all ultimately communicating with the underlying LMX engine.</p>
                </div>
            </section>

            <section id="competitors" class="flex flex-col gap-8 pt-8 border-t border-white/10">
                <h2 class="text-3xl font-semibold text-text_primary">The Competitive Landscape</h2>
                <div class="text-text_secondary leading-relaxed text-lg">
                    <p>Why build <span class="text-opta">Opta</span> LMX when other local runners exist? The local AI space is highly fragmented. Solutions usually force a tradeoff between performance, automation, and user experience. LMX was engineered specifically to solve the bottleneck of programmatic bot autonomy on Apple Silicon.</p>
                </div>
                
                <div class="glass border border-white/10 rounded-2xl overflow-hidden mt-4">
                    <table class="w-full text-left border-collapse">
                        <thead>
                            <tr class="bg-surface border-b border-white/10">
                                <th class="py-4 px-6 font-semibold text-text_primary font-sans text-sm tracking-wide w-1/4">Platform</th>
                                <th class="py-4 px-6 font-semibold text-text_primary font-sans text-sm tracking-wide w-3/4">The Architecture Constraint</th>
                            </tr>
                        </thead>
                        <tbody class="text-sm divide-y divide-white/5 bg-void/50">
                            <tr class="hover:bg-white/5 transition-colors">
                                <td class="py-4 px-6 text-text_primary font-semibold">LM Studio</td>
                                <td class="py-4 px-6 text-text_secondary leading-relaxed">Requires a human operator to click download buttons, drag GPU sliders, and manage models. It bundles its own <code class="text-text_muted">llama.cpp</code>, meaning new model architectures (like GLM-5) are strictly blocked until LM Studio releases a GUI update. Bots cannot operate it autonomously.</td>
                            </tr>
                            <tr class="hover:bg-white/5 transition-colors">
                                <td class="py-4 px-6 text-text_primary font-semibold">Ollama</td>
                                <td class="py-4 px-6 text-text_secondary leading-relaxed">Excellent developer CLI, but written mostly in Go/C++. It often lags behind native Apple Silicon MLX optimization, lacking the zero-copy memory architecture that natively integrated Python/MLX-LM wrappers provide.</td>
                            </tr>
                            <tr class="hover:bg-white/5 transition-colors">
                                <td class="py-4 px-6 text-text_primary font-semibold">vLLM</td>
                                <td class="py-4 px-6 text-text_secondary leading-relaxed">Server-grade and exceptionally fast, but heavily tailored toward Linux/CUDA environments. Running it cleanly and natively on macOS unified memory remains an afterthought.</td>
                            </tr>
                            <tr class="hover:bg-[rgba(168,85,247,0.05)] transition-colors border-l-2 border-l-violet bg-[rgba(168,85,247,0.02)]">
                                <td class="py-4 px-6 text-violet font-bold"><span class="text-opta">Opta</span> LMX</td>
                                <td class="py-4 px-6 text-text_secondary leading-relaxed">Headless-first, deeply integrated with Apple's <code class="text-violet">MLX</code> framework for 15-30% faster execution via zero-copy unified memory. Exposes a full Admin API allowing autonomous bots to download, switch, and route models without human intervention. Written in Python, allowing day-zero support for new model architectures.</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <section id="architecture" class="flex flex-col gap-8 pt-8 border-t border-white/10">
                <h2 class="text-3xl font-semibold text-text_primary">Architecture & Memory</h2>
                <div class="text-text_secondary leading-relaxed text-lg">
                    <p>LMX solves the hardest problem in local AI: Out-Of-Memory (OOM) crashes. It achieves this via a three-tier memory abstraction that dynamically monitors system limits and gracefully degrades performance rather than terminating the daemon.</p>
                </div>
                
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mt-4">
                    <div class="obsidian p-6 flex flex-col gap-4 relative overflow-hidden">
                        <div class="absolute top-0 right-0 w-24 h-24 bg-violet/10 rounded-bl-full"></div>
                        <div class="w-10 h-10 rounded bg-violet/10 border border-violet/30 flex items-center justify-center flex-shrink-0 z-10">
                            <i data-lucide="microchip" class="text-violet w-5 h-5"></i>
                        </div>
                        <h3 class="text-text_primary font-semibold text-lg z-10">Tier 1: Unified VRAM</h3>
                        <p class="text-text_secondary text-sm leading-relaxed z-10">The absolute fastest tier. LMX attempts to map 100% of the model's weights directly into Apple Silicon's unified memory, leveraging zero-copy overhead for maximum tokens-per-second.</p>
                    </div>
                    
                    <div class="obsidian p-6 flex flex-col gap-4 relative overflow-hidden">
                        <div class="absolute top-0 right-0 w-24 h-24 bg-amber/10 rounded-bl-full"></div>
                        <div class="w-10 h-10 rounded bg-amber/10 border border-amber/30 flex items-center justify-center flex-shrink-0 z-10">
                            <i data-lucide="cpu" class="text-amber w-5 h-5"></i>
                        </div>
                        <h3 class="text-text_primary font-semibold text-lg z-10">Tier 2: CPU Offload</h3>
                        <p class="text-text_secondary text-sm leading-relaxed z-10">If system memory reaches critical capacity, LMX mathematically calculates which transformer layers can fit and dynamically spills the remainder to the CPU. Inference slows down, but the process never panics.</p>
                    </div>

                    <div class="obsidian p-6 flex flex-col gap-4 relative overflow-hidden">
                        <div class="absolute top-0 right-0 w-24 h-24 bg-text_muted/10 rounded-bl-full"></div>
                        <div class="w-10 h-10 rounded bg-text_muted/10 border border-text_muted/30 flex items-center justify-center flex-shrink-0 z-10">
                            <i data-lucide="hard-drive" class="text-text_muted w-5 h-5"></i>
                        </div>
                        <h3 class="text-text_primary font-semibold text-lg z-10">Tier 3: Disk KV Swap</h3>
                        <p class="text-text_secondary text-sm leading-relaxed z-10">During massive document ingestion (100k+ tokens), the Key-Value (KV) cache grows exponentially. LMX can page older contextual states to NVMe storage to preserve space.</p>
                    </div>
                </div>
            </section>

            <section id="capabilities" class="flex flex-col gap-8 pt-8 border-t border-white/10">
                <h2 class="text-3xl font-semibold text-text_primary">Core Capabilities Deep-Dive</h2>
                
                <div class="flex flex-col gap-12 mt-4">
                    <!-- Deep Feature 1 -->
                    <div class="flex gap-6 items-start">
                        <div class="mt-1 w-12 h-12 rounded-xl bg-violet/10 border border-violet/30 flex items-center justify-center flex-shrink-0">
                            <i data-lucide="route" class="text-violet w-6 h-6"></i>
                        </div>
                        <div class="flex flex-col gap-3">
                            <h3 class="text-xl font-semibold text-text_primary">Smart Routing & Tool Pass-Through</h3>
                            <p class="text-text_secondary leading-relaxed">Because <span class="text-opta">Opta</span> LMX serves a strictly OpenAI-compatible <code class="text-neon_green">/v1/chat/completions</code> endpoint, it supports seamless tool and function calling. When you request a complex coding task via the <a href="/guides/cli" class="app-link link-cli">Opta CLI</a>, the Smart Router analyzes the payload and can autonomously wake up the optimal model for the job, handling the function-calling JSON structures natively.</p>
                        </div>
                    </div>
                    
                    <!-- Deep Feature 2 -->
                    <div class="flex gap-6 items-start">
                        <div class="mt-1 w-12 h-12 rounded-xl bg-violet/10 border border-violet/30 flex items-center justify-center flex-shrink-0">
                            <i data-lucide="repeat-2" class="text-violet w-6 h-6"></i>
                        </div>
                        <div class="flex flex-col gap-3">
                            <h3 class="text-xl font-semibold text-text_primary">Zero-Downtime Hot-Swaps</h3>
                            <p class="text-text_secondary leading-relaxed">Unlike traditional setups, LMX operates independently of the model it's currently running. You can issue a command to switch from an 8B instruct model to a massive 70B coder model in milliseconds. LMX gracefully dumps the unified memory and streams the new GGUF/MLX safetensors from disk without restarting the host port listener.</p>
                        </div>
                    </div>
                    
                    <!-- Deep Feature 3 -->
                    <div class="flex gap-6 items-start">
                        <div class="mt-1 w-12 h-12 rounded-xl bg-violet/10 border border-violet/30 flex items-center justify-center flex-shrink-0">
                            <i data-lucide="layers" class="text-violet w-6 h-6"></i>
                        </div>
                        <div class="flex flex-col gap-3">
                            <h3 class="text-xl font-semibold text-text_primary">Concurrent Request Queuing</h3>
                            <p class="text-text_secondary leading-relaxed">Built for agentic workflows. When multiple autonomous bots hit the LMX server simultaneously, it doesn't drop packets or throw 503s. It queues the requests and processes them sequentially (or via batched inference, depending on the model), ensuring reliable execution across the <span class="text-opta">Opta</span> ecosystem.</p>
                        </div>
                    </div>
                </div>
            </section>

            <section id="features" class="flex flex-col gap-8 pt-8 border-t border-white/10">
                <h2 class="text-3xl font-semibold text-text_primary">Full Feature Matrix</h2>
                <p class="text-text_secondary leading-relaxed text-lg">Beyond its core capabilities, LMX is packed with infrastructure-level features that make it a robust daemon.</p>
                
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mt-2">
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">GGUF & Safetensors Support</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">SSE Streaming Responses</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">Headless launchd Daemon</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">Autonomous HuggingFace Downloads</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">Drop-in LM Studio Port Binding (1234/8080)</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">Live System Status Admin API</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">YAML Configuration with Hot-Reload</span>
                    </div>
                    <div class="glass p-4 rounded-lg border border-white/5 flex items-center gap-3">
                        <i data-lucide="check-circle-2" class="w-5 h-5 text-neon_green"></i>
                        <span class="text-text_primary font-medium text-sm">X-Admin-Key Authentication</span>
                    </div>
                </div>
            </section>

            <section id="workflows" class="flex flex-col gap-8 pt-8 border-t border-white/10">
                <h2 class="text-3xl font-semibold text-text_primary">Integrated Workflows</h2>
                <div class="text-text_secondary leading-relaxed text-lg">
                    <p>Because LMX is unopinionated about how you connect to it, it serves as the ultimate backend for the entire ecosystem and your custom tools.</p>
                </div>

                <div class="obsidian p-8 flex flex-col gap-6">
                    <h3 class="text-text_primary font-semibold text-xl">The "Opta Standard" Flow</h3>
                    <p class="text-text_secondary">The recommended way to interact with LMX locally is combining it with the rest of the <span class="text-opta">Opta</span> stack:</p>
                    <ol class="list-decimal pl-6 text-text_secondary space-y-4">
                        <li>Install the system using <a href="/guides/init" class="app-link link-init">Opta Init</a>. This sets up the daemon to run on boot via macOS LaunchDaemons.</li>
                        <li>Use the <a href="/guides/cli" class="app-link link-cli">Opta CLI</a> in your terminal for fast, developer-centric interactions (e.g. <code class="text-violet">opta run phi-3</code>). The CLI inherently knows how to speak to LMX's internal Admin API.</li>
                        <li>For visual management, open the <a href="/guides/dashboard" class="app-link link-dashboard">Opta Local Dashboard</a> to see VRAM usage, verify downloaded models, and monitor active port connections.</li>
                        <li>Ensure multi-device continuity by linking your settings to <a href="/guides/accounts" class="app-link link-accounts">Opta Accounts</a>, maintaining your LMX preferences wherever you work.</li>
                    </ol>
                </div>
            </section>
            
            <div class="h-32"></div>
        </main>
    </div>
    <script>
        lucide.createIcons();
        
        document.addEventListener("DOMContentLoaded", () => {
            const sections = document.querySelectorAll("section");
            const navLinks = document.querySelectorAll(".toc-link");

            const observer = new IntersectionObserver((entries) => {
                entries.forEach((entry) => {
                    if (entry.isIntersecting) {
                        navLinks.forEach((link) => {
                            link.classList.remove("active");
                            if (link.getAttribute("data-target") === entry.target.id) {
                                link.classList.add("active");
                            }
                        });
                    }
                });
            }, { rootMargin: "-100px 0px -60% 0px", threshold: 0 });

            sections.forEach((section) => observer.observe(section));
        });
    </script>
</body>
</html>