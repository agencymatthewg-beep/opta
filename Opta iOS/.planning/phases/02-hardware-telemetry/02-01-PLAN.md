---
phase: 02-hardware-telemetry
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [mcp-server/pyproject.toml, mcp-server/src/opta_mcp/__init__.py, mcp-server/src/opta_mcp/server.py, mcp-server/src/opta_mcp/telemetry.py]
autonomous: true
---

<objective>
Create a Python MCP server that exposes hardware telemetry (CPU, RAM, disk, GPU) as MCP tools.

Purpose: Provide the backend data source for real-time system monitoring in Opta.
Output: Working MCP server that can be invoked by Tauri to get hardware stats.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Python MCP server project structure</name>
  <files>mcp-server/pyproject.toml, mcp-server/src/opta_mcp/__init__.py, mcp-server/src/opta_mcp/server.py</files>
  <action>
    Create a new Python package in `mcp-server/` directory at project root:

    1. Create directory structure:
       ```
       mcp-server/
       ├── pyproject.toml
       ├── README.md
       └── src/
           └── opta_mcp/
               ├── __init__.py
               └── server.py
       ```

    2. pyproject.toml:
       - Name: opta-mcp-server
       - Python >= 3.10
       - Dependencies: mcp (Anthropic MCP SDK), psutil, GPUtil (optional GPU)
       - Entry point: `opta-mcp = "opta_mcp.server:main"`

    3. server.py:
       - Import mcp SDK
       - Create MCP server instance
       - Register placeholder tools (will implement in Task 2)
       - Main function to start server with stdio transport

    Use `mcp` package from Anthropic (pip install mcp). Server should:
    - Use stdio transport (stdin/stdout for IPC with Tauri)
    - Follow MCP tool registration patterns
  </action>
  <verify>
    - `cd mcp-server && pip install -e .` succeeds
    - `python -c "from opta_mcp.server import main"` imports without error
  </verify>
  <done>MCP server package created with proper structure, installs successfully</done>
</task>

<task type="auto">
  <name>Task 2: Implement CPU/RAM/disk telemetry with psutil</name>
  <files>mcp-server/src/opta_mcp/telemetry.py, mcp-server/src/opta_mcp/server.py</files>
  <action>
    Create telemetry.py with functions to gather system stats:

    1. `get_cpu_info()` returns:
       - percent: Current CPU usage (0-100)
       - cores: Number of physical cores
       - threads: Number of logical processors
       - frequency_mhz: Current frequency (if available)
       - per_core_percent: List of per-core usage

    2. `get_memory_info()` returns:
       - total_gb: Total RAM in GB
       - used_gb: Used RAM in GB
       - available_gb: Available RAM in GB
       - percent: Usage percentage

    3. `get_disk_info()` returns:
       - total_gb: Total disk space
       - used_gb: Used space
       - free_gb: Free space
       - percent: Usage percentage
       (Use primary disk / root partition)

    4. `get_system_snapshot()` returns all of the above combined.

    Register MCP tools in server.py:
    - `get_cpu` - Returns CPU telemetry
    - `get_memory` - Returns RAM telemetry
    - `get_disk` - Returns disk telemetry
    - `get_system_snapshot` - Returns all telemetry at once

    Use psutil for all metrics. Handle exceptions gracefully (return null/default if metric unavailable).
  </action>
  <verify>
    - Run `python -c "from opta_mcp.telemetry import get_system_snapshot; print(get_system_snapshot())"` shows valid JSON
    - CPU percent is 0-100, memory shows realistic values
  </verify>
  <done>CPU, RAM, and disk telemetry working via psutil, exposed as MCP tools</done>
</task>

<task type="auto">
  <name>Task 3: Add GPU detection with graceful fallback</name>
  <files>mcp-server/src/opta_mcp/telemetry.py, mcp-server/src/opta_mcp/server.py</files>
  <action>
    Add GPU monitoring with cross-platform fallback strategy:

    1. `get_gpu_info()` returns:
       - available: boolean (GPU detected or not)
       - name: GPU name (e.g., "NVIDIA GeForce RTX 3080")
       - memory_total_gb: Total VRAM
       - memory_used_gb: Used VRAM
       - memory_percent: VRAM usage percentage
       - temperature_c: GPU temp (if available)
       - utilization_percent: GPU compute usage (if available)

    2. Detection strategy (try in order):
       a. Try GPUtil for NVIDIA GPUs (nvidia-smi based)
       b. Try pynvml directly if GPUtil fails
       c. On macOS: Try py-metal or subprocess call to system_profiler
       d. Fallback: Return {available: false, name: "No GPU detected"}

    3. Update `get_system_snapshot()` to include GPU info.

    4. Add `get_gpu` MCP tool to server.py.

    IMPORTANT: GPU detection should NEVER crash. Wrap in try/except, return fallback on any error.
    Make GPUtil an optional dependency (extras_require in pyproject.toml).
  </action>
  <verify>
    - On machine with GPU: Shows GPU name and stats
    - On machine without GPU: Returns {available: false} gracefully
    - No crashes or exceptions in either case
  </verify>
  <done>GPU telemetry with graceful fallback for all platforms, MCP tool registered</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pip install -e mcp-server/` succeeds
- [ ] All telemetry functions return valid data
- [ ] MCP server starts without errors
- [ ] `get_system_snapshot` returns CPU, RAM, disk, and GPU info
- [ ] No crashes on missing GPU
</verification>

<success_criteria>
- All tasks completed
- Python MCP server package created and installable
- CPU, RAM, disk, GPU telemetry working
- MCP tools registered and callable
- Ready for Tauri integration in Plan 02-02
</success_criteria>

<output>
After completion, create `.planning/phases/02-hardware-telemetry/02-01-SUMMARY.md`
</output>
