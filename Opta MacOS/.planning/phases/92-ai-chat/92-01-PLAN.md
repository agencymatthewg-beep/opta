---
phase: 92
plan: 01
title: AI Chat View and Message System
type: feature
wave: 1
depends_on: []
files_modified:
  - opta-native/OptaApp/OptaApp/Models/ChatModels.swift
  - opta-native/OptaApp/OptaApp/Views/AiChat/AiChatView.swift
  - opta-native/OptaApp/OptaApp/Views/AiChat/ChatMessageBubble.swift
  - opta-native/OptaApp/OptaApp/Views/AiChat/ChatInputView.swift
  - opta-native/OptaApp/OptaApp/OptaAppApp.swift
  - opta-native/OptaApp/OptaApp.xcodeproj/project.pbxproj
autonomous: true
---

<objective>
Create the AI Chat interface with message display, input field, and streaming text support.
This provides the complete visual chat experience following the obsidian+violet design language.
Messages display with user/assistant bubbles, the input field supports multi-line with send button,
and streaming responses show character-by-character with a typing indicator.
</objective>

<execution_context>
- Architecture: SwiftUI views with @Observable ChatViewModel (Swift-side, not Crux)
- Design: Obsidian base (0A0A0F), Electric Violet (8B5CF6) accents, dark background (09090B)
- Pattern: Similar to OptimizeView.swift - ScrollView + VStack, OrganicMotion springs
- Navigation: .aiChat page already exists in PageViewModel enum and CircularMenuNavigation
- The chat state lives in Swift (not Rust core) since LLM calls are Swift-side (MLX/network)
</execution_context>

<context>
@opta-native/OptaApp/OptaApp/Models/OptaViewModel.swift (PageViewModel enum, event patterns)
@opta-native/OptaApp/OptaApp/Views/OptimizeView.swift (view structure pattern)
@opta-native/OptaApp/OptaApp/OptaAppApp.swift (navigation switch, placeholder to replace)
@opta-native/OptaApp/OptaApp.xcodeproj/project.pbxproj (file registration)
</context>

<tasks>

<task id="1" type="auto">
<title>Create Chat Message Models and ChatViewModel</title>
<description>
Create ChatModels.swift with message types and an @Observable ChatViewModel class.
The ViewModel manages conversation state, message list, input text, and streaming state.
This is a Swift-side ViewModel (not Crux) since LLM interactions are platform-specific.
</description>
<files>
  - CREATE: opta-native/OptaApp/OptaApp/Models/ChatModels.swift
</files>
<action>
Create ChatModels.swift with:

1. `ChatMessage` struct:
   - `id: UUID`
   - `role: MessageRole` (enum: .user, .assistant, .system)
   - `content: String`
   - `timestamp: Date`
   - `isStreaming: Bool` (true while response is being generated)
   - `metadata: MessageMetadata?` (optional: model used, tokens, latency)

2. `MessageRole` enum: `.user`, `.assistant`, `.system`

3. `MessageMetadata` struct:
   - `model: String` (e.g. "local-mlx" or "claude-sonnet")
   - `tokensUsed: Int?`
   - `latencyMs: Int?`
   - `routedLocally: Bool`

4. `ChatViewModel` class (@Observable):
   - `messages: [ChatMessage] = []`
   - `inputText: String = ""`
   - `isGenerating: Bool = false`
   - `streamingText: String = ""`
   - `selectedModel: LLMModel = .auto` (enum: .auto, .local, .cloud)
   - `conversationContext: String = ""` (system prompt context)
   - `func sendMessage()` - creates user message, triggers generation placeholder
   - `func cancelGeneration()` - stops current generation
   - `func clearConversation()` - resets messages array
   - `func addSystemContext(_ context: String)` - updates system prompt

5. `LLMModel` enum: `.auto`, `.local`, `.cloud`
   - `var displayName: String` computed property
   - `var icon: String` computed property (SF Symbol)

Follow the Codable pattern from OptaViewModel for any serializable types.
Use `@Observable` (not `@Published`) matching modern SwiftUI patterns.
</action>
<verify>
File compiles without errors. ChatViewModel can be instantiated and messages added.
</verify>
<done>ChatModels.swift exists with ChatMessage, MessageRole, MessageMetadata, ChatViewModel, and LLMModel types.</done>
</task>

<task id="2" type="auto">
<title>Create AiChatView, ChatMessageBubble, and ChatInputView</title>
<description>
Build the complete chat UI with three components:
- AiChatView: Main container with header, message list, and input
- ChatMessageBubble: Individual message rendering (user vs assistant styling)
- ChatInputView: Multi-line text input with send button and model selector
</description>
<files>
  - CREATE: opta-native/OptaApp/OptaApp/Views/AiChat/AiChatView.swift
  - CREATE: opta-native/OptaApp/OptaApp/Views/AiChat/ChatMessageBubble.swift
  - CREATE: opta-native/OptaApp/OptaApp/Views/AiChat/ChatInputView.swift
</files>
<action>
**AiChatView.swift:**
- Header: "AI Chat" title + back button (same pattern as OptimizeView header)
- Model selector: Picker with .auto/.local/.cloud options
- ScrollViewReader + ScrollView with message list
- Auto-scroll to bottom on new messages
- Empty state: icon + "Ask Opta anything about your system" prompt
- Suggestion chips when empty: "Optimize my CPU", "What's using my RAM?", "Reduce fan noise"
- ChatInputView pinned at bottom
- Background: Color(hex: "09090B")
- Use `@Environment(\.colorTemperature)` for violet accents

**ChatMessageBubble.swift:**
- User messages: right-aligned, violet-tinted background (8B5CF6 at 0.15 opacity)
- Assistant messages: left-aligned, obsidian panel (0A0A0F with border)
- Timestamp below message (relative time: "just now", "2m ago")
- Streaming indicator: animated dots when `isStreaming == true`
- Message text: .white for user, .white.opacity(0.9) for assistant
- Corner radius: 16pt with asymmetric corners (flat on sender side)
- Metadata badge: small model indicator when metadata present

**ChatInputView.swift:**
- TextEditor (multi-line, max 4 lines before scroll)
- Send button: violet circle with arrow.up icon
- Send button disabled when input empty or isGenerating
- Cancel button appears during generation (stop.circle)
- Keyboard shortcut: Cmd+Enter to send
- Placeholder text: "Message Opta..."
- Background: obsidian panel with violet border glow when focused
- Model indicator pill showing current selection
</action>
<verify>
All three files compile. AiChatView can be previewed in Xcode with mock data.
Message bubbles render correctly for both user and assistant roles.
Input field accepts text and send button triggers sendMessage().
</verify>
<done>AiChatView.swift, ChatMessageBubble.swift, and ChatInputView.swift exist in Views/AiChat/ directory with complete UI implementation.</done>
</task>

<task id="3" type="auto">
<title>Register Files in Xcode and Wire Navigation</title>
<description>
Add all new files to the Xcode project and replace the placeholder in OptaAppApp.swift
with the actual AiChatView. Create the AiChat group in the project navigator.
</description>
<files>
  - MODIFY: opta-native/OptaApp/OptaApp.xcodeproj/project.pbxproj
  - MODIFY: opta-native/OptaApp/OptaApp/OptaAppApp.swift
</files>
<action>
1. In project.pbxproj:
   - Add ChatModels.swift to Models group
   - Create AiChat group under Views
   - Add AiChatView.swift, ChatMessageBubble.swift, ChatInputView.swift to AiChat group
   - Add all files to PBXBuildFile, PBXFileReference, and appropriate PBXGroup sections
   - Use unique file IDs that don't collide with existing entries

2. In OptaAppApp.swift:
   - Replace the `.aiChat` placeholder case:
     ```swift
     case .aiChat:
         AiChatView()
     ```
   - Remove the old placeholder that shows "AI Chat" / "Coming in Phase 76"

3. Verify build succeeds with `xcodebuild -project ... -scheme OptaApp build`
</action>
<verify>
`xcodebuild build` passes. Navigating to AI Chat from circular menu shows AiChatView.
</verify>
<done>All files registered in Xcode project. Navigation to .aiChat shows AiChatView instead of placeholder.</done>
</task>

</tasks>

<verification>
1. Build passes: `xcodebuild -project opta-native/OptaApp/OptaApp.xcodeproj -scheme OptaApp build`
2. AI Chat page accessible via circular menu navigation
3. Messages can be typed and sent (creates user bubble, placeholder assistant response)
4. Streaming text animation works on assistant messages
5. Empty state shows suggestion chips
6. Design matches obsidian+violet aesthetic
</verification>

<success_criteria>
- [ ] ChatModels.swift with ChatMessage, ChatViewModel, LLMModel types
- [ ] AiChatView.swift with header, message list, empty state, suggestions
- [ ] ChatMessageBubble.swift with user/assistant styling and streaming indicator
- [ ] ChatInputView.swift with multi-line input, send/cancel, model selector
- [ ] Files registered in Xcode project (no build errors)
- [ ] Navigation wired: .aiChat case shows AiChatView
- [ ] Obsidian+violet design language consistent with app
</success_criteria>

<output>
SUMMARY.md documenting:
- Files created and their purposes
- Architecture decisions (Swift-side ViewModel vs Crux)
- Design patterns used
- Build verification results
</output>
