---
phase: 08.1-adaptive-intelligence
plan: 02
type: execute
wave: 2
depends_on: ["08.1-01"]
files_modified: [mcp-server/src/opta_mcp/patterns.py, mcp-server/src/opta_mcp/optimizer.py, mcp-server/src/opta_mcp/server.py, src/hooks/useOptimizer.ts]
autonomous: true
---

<objective>
Implement pattern learning engine that analyzes user optimization choices to discover preferences and aversions.

Purpose: Track when users accept vs revert optimizations, analyze patterns across games and setting types, and build a preference model that improves recommendations over time.

Output: Pattern detection algorithms, choice tracking integration, and pattern analysis functions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/MUST_HAVE.md
@.planning/phases/08.1-adaptive-intelligence/08.1-01-SUMMARY.md

# Existing optimization flow to extend:
@mcp-server/src/opta_mcp/optimizer.py
@src/hooks/useOptimizer.ts
@src/types/optimizer.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Python patterns module</name>
  <files>mcp-server/src/opta_mcp/patterns.py</files>
  <action>
Create patterns.py with pattern detection algorithms:

```python
from dataclasses import dataclass
from typing import List, Optional
from pathlib import Path
import json

@dataclass
class OptimizationChoice:
    """Records a single user choice on an optimization."""
    game_id: str
    game_name: str
    setting_category: str  # 'graphics', 'launch_options', 'priority'
    setting_key: str
    original_value: any
    new_value: any
    action: str  # 'accepted', 'reverted', 'modified'
    timestamp: float

@dataclass
class DetectedPattern:
    """A pattern discovered from analyzing choices."""
    pattern_type: str  # 'preference', 'aversion', 'timing'
    setting_category: str
    setting_key: str
    confidence: float  # 0-1 based on sample count and consistency
    sample_count: int
    description: str  # Human-readable explanation
    last_updated: float

def record_choice(choice: OptimizationChoice) -> None:
    """Record a user's optimization choice to ~/.opta/choices/."""
    # Append to choices log file
    # Structure: ~/.opta/choices/choices_log.jsonl (one JSON per line)

def analyze_patterns() -> List[DetectedPattern]:
    """Analyze all recorded choices to detect patterns."""
    # Load all choices from log
    # Group by setting_category + setting_key
    # Calculate acceptance rate per setting type
    # Patterns:
    #   - preference: >70% acceptance rate, 3+ samples
    #   - aversion: <30% acceptance rate, 3+ samples
    #   - timing: if user consistently optimizes at certain times

def get_user_patterns() -> List[DetectedPattern]:
    """Get current detected patterns for the user."""
    # Return cached patterns from profile or re-analyze if stale

def update_profile_patterns(profile_path: Path) -> None:
    """Update the user profile with latest detected patterns."""
    # Load profile, run analyze_patterns(), save to profile.patterns
```

Key pattern detection logic:
1. Group choices by `setting_category` + `setting_key`
2. Calculate acceptance_rate = accepted / (accepted + reverted)
3. If acceptance_rate > 0.7 and samples >= 3: mark as 'preference'
4. If acceptance_rate < 0.3 and samples >= 3: mark as 'aversion'
5. Generate human-readable descriptions:
   - "You typically accept FPS-boosting optimizations"
   - "You tend to revert changes to visual quality settings"

Storage: `~/.opta/choices/choices_log.jsonl` (append-only log)
  </action>
  <verify>Python imports work: `python -c "from opta_mcp.patterns import analyze_patterns"`</verify>
  <done>Pattern detection algorithms implemented, can identify preferences and aversions from choice history</done>
</task>

<task type="auto">
  <name>Task 2: Integrate choice tracking into optimizer</name>
  <files>mcp-server/src/opta_mcp/optimizer.py, mcp-server/src/opta_mcp/server.py</files>
  <action>
Modify optimizer.py to emit choice events:

1. Add new function `record_optimization_choice()`:
```python
from .patterns import record_choice, OptimizationChoice

def record_optimization_choice(
    game_id: str,
    game_name: str,
    setting_category: str,
    setting_key: str,
    original_value: any,
    new_value: any,
    action: str  # 'accepted', 'reverted'
) -> dict:
    """Record a user's choice for pattern learning."""
    choice = OptimizationChoice(
        game_id=game_id,
        game_name=game_name,
        setting_category=setting_category,
        setting_key=setting_key,
        original_value=original_value,
        new_value=new_value,
        action=action,
        timestamp=time.time()
    )
    record_choice(choice)
    return {"status": "recorded", "choice": asdict(choice)}
```

2. Add to server.py tool list:
```python
Tool(
    name="record_optimization_choice",
    description="Record user's choice on an optimization for pattern learning",
    inputSchema={
        "type": "object",
        "properties": {
            "game_id": {"type": "string"},
            "game_name": {"type": "string"},
            "setting_category": {"type": "string"},
            "setting_key": {"type": "string"},
            "original_value": {},
            "new_value": {},
            "action": {"type": "string", "enum": ["accepted", "reverted"]}
        },
        "required": ["game_id", "game_name", "setting_category", "action"]
    }
),
Tool(
    name="analyze_patterns",
    description="Analyze user choices and return detected patterns",
    inputSchema={"type": "object", "properties": {}}
),
Tool(
    name="get_user_patterns",
    description="Get current detected patterns for the user",
    inputSchema={"type": "object", "properties": {}}
)
```

3. Add handlers in handle_call_tool for the new tools.
  </action>
  <verify>MCP tools work: test via Tauri command that calls record_optimization_choice</verify>
  <done>Choice events are recorded when user accepts/reverts, MCP tools available</done>
</task>

<task type="auto">
  <name>Task 3: Update React hook to record choices</name>
  <files>src/hooks/useOptimizer.ts</files>
  <action>
Modify useOptimizer.ts to record choices after optimization actions:

1. Add new method `recordChoice`:
```typescript
const recordChoice = useCallback(async (
  gameId: string,
  gameName: string,
  settingCategory: string,
  settingKey: string,
  originalValue: unknown,
  newValue: unknown,
  action: 'accepted' | 'reverted'
) => {
  try {
    await invoke('record_optimization_choice', {
      gameId,
      gameName,
      settingCategory,
      settingKey,
      originalValue,
      newValue,
      action
    });
  } catch (e) {
    console.error('Failed to record choice:', e);
    // Non-blocking - don't throw, just log
  }
}, []);
```

2. Modify `applyOptimization` to automatically record 'accepted' for each setting applied.

3. Modify `revertOptimization` to automatically record 'reverted' for each setting reverted.

4. Export `recordChoice` in the hook return for manual recording if needed.

Note: This is "fire and forget" - we don't want choice recording failures to block the main optimization flow. Wrap in try/catch and log errors but don't propagate.
  </action>
  <verify>npm run build passes, choices are recorded in ~/.opta/choices/choices_log.jsonl after optimization</verify>
  <done>Choices automatically recorded when user accepts or reverts optimizations</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build` succeeds without errors
- [ ] `cargo build` succeeds without errors
- [ ] Applying an optimization records 'accepted' choice
- [ ] Reverting an optimization records 'reverted' choice
- [ ] `analyze_patterns` returns detected patterns after sufficient choices
- [ ] Patterns have human-readable descriptions
</verification>

<success_criteria>
- All tasks completed
- Choices logged to ~/.opta/choices/choices_log.jsonl
- Pattern detection identifies preferences (>70% accept) and aversions (<30% accept)
- Patterns include confidence scores and sample counts
- Non-blocking: choice recording failures don't break optimization flow
</success_criteria>

<output>
After completion, create `.planning/phases/08.1-adaptive-intelligence/08.1-02-SUMMARY.md`
</output>
