---
phase: 02-hardware-telemetry
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified: [src-tauri/tauri.conf.json, src-tauri/src/main.rs, src-tauri/src/telemetry.rs, src/hooks/useTelemetry.ts, src/types/telemetry.ts]
autonomous: true
---

<objective>
Integrate the Python MCP server with Tauri so the frontend can request hardware telemetry.

Purpose: Bridge the Python telemetry backend to the React frontend via Tauri commands.
Output: Tauri commands that invoke MCP tools and return telemetry data to the UI.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-hardware-telemetry/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Configure Tauri sidecar for Python MCP server</name>
  <files>src-tauri/tauri.conf.json, src-tauri/Cargo.toml</files>
  <action>
    Configure Tauri to bundle and spawn the Python MCP server as a sidecar:

    1. In tauri.conf.json, add sidecar configuration:
       ```json
       "bundle": {
         "externalBin": [
           "binaries/opta-mcp"
         ]
       }
       ```

    2. Create a shell script wrapper at `src-tauri/binaries/`:
       - `opta-mcp-x86_64-apple-darwin` (macOS Intel)
       - `opta-mcp-aarch64-apple-darwin` (macOS ARM)
       - `opta-mcp-x86_64-pc-windows-msvc.exe` (Windows)
       - `opta-mcp-x86_64-unknown-linux-gnu` (Linux)

       Each script should:
       - Activate the Python venv if present
       - Run `python -m opta_mcp.server`

    3. For development, use a simpler approach:
       - Detect if running in dev mode
       - If dev: spawn `python -m opta_mcp.server` directly
       - If prod: use bundled sidecar

    4. Add `tauri-plugin-shell` to Cargo.toml if not present (for Command API).

    NOTE: Full cross-platform bundling is complex. For now, focus on macOS development path.
    Document the production bundling strategy in a comment for Phase 10.
  </action>
  <verify>
    - tauri.conf.json has externalBin configured
    - Sidecar script exists for current platform
    - No Tauri build errors
  </verify>
  <done>Tauri configured to spawn Python MCP server as sidecar</done>
</task>

<task type="auto">
  <name>Task 2: Create Rust commands to invoke MCP tools</name>
  <files>src-tauri/src/telemetry.rs, src-tauri/src/main.rs</files>
  <action>
    Create Rust module to communicate with MCP server:

    1. Create `src-tauri/src/telemetry.rs`:

       ```rust
       use std::process::{Command, Stdio};
       use std::io::{BufRead, BufReader, Write};
       use serde::{Deserialize, Serialize};
       use tauri::command;

       #[derive(Serialize, Deserialize)]
       pub struct CpuInfo {
           pub percent: f64,
           pub cores: u32,
           pub threads: u32,
           pub frequency_mhz: Option<f64>,
       }

       // Similar structs for MemoryInfo, DiskInfo, GpuInfo, SystemSnapshot
       ```

    2. Implement `get_system_telemetry` command:
       - Spawn Python MCP server process (if not running)
       - Send JSON-RPC request for `get_system_snapshot` tool
       - Parse response and return to frontend
       - Handle errors gracefully

    3. For simplicity in v1, use subprocess per-request:
       - Run `python -c "from opta_mcp.telemetry import get_system_snapshot; import json; print(json.dumps(get_system_snapshot()))"`
       - Parse stdout as JSON
       - Return typed struct

       NOTE: Full MCP stdio transport is more complex. This simpler approach works for MVP.
       Can optimize to persistent connection in Phase 10.

    4. Register command in main.rs:
       ```rust
       mod telemetry;

       fn main() {
           tauri::Builder::default()
               .invoke_handler(tauri::generate_handler![
                   telemetry::get_system_telemetry
               ])
               .run(tauri::generate_context!())
               .expect("error while running tauri application");
       }
       ```
  </action>
  <verify>
    - `cargo check` passes in src-tauri/
    - Rust structs match Python telemetry output
    - Command is registered in Tauri
  </verify>
  <done>Rust commands created to fetch telemetry from Python backend</done>
</task>

<task type="auto">
  <name>Task 3: Wire up frontend to receive telemetry data</name>
  <files>src/hooks/useTelemetry.ts, src/types/telemetry.ts</files>
  <action>
    Create TypeScript types and React hook for telemetry:

    1. Create `src/types/telemetry.ts`:
       ```typescript
       export interface CpuInfo {
         percent: number;
         cores: number;
         threads: number;
         frequency_mhz: number | null;
         per_core_percent?: number[];
       }

       export interface MemoryInfo {
         total_gb: number;
         used_gb: number;
         available_gb: number;
         percent: number;
       }

       export interface DiskInfo {
         total_gb: number;
         used_gb: number;
         free_gb: number;
         percent: number;
       }

       export interface GpuInfo {
         available: boolean;
         name: string;
         memory_total_gb?: number;
         memory_used_gb?: number;
         memory_percent?: number;
         temperature_c?: number;
         utilization_percent?: number;
       }

       export interface SystemSnapshot {
         cpu: CpuInfo;
         memory: MemoryInfo;
         disk: DiskInfo;
         gpu: GpuInfo;
         timestamp: string;
       }
       ```

    2. Create `src/hooks/useTelemetry.ts`:
       ```typescript
       import { useState, useEffect, useCallback } from 'react';
       import { invoke } from '@tauri-apps/api/core';
       import { SystemSnapshot } from '../types/telemetry';

       export function useTelemetry(pollInterval = 2000) {
         const [telemetry, setTelemetry] = useState<SystemSnapshot | null>(null);
         const [error, setError] = useState<string | null>(null);
         const [loading, setLoading] = useState(true);

         const fetchTelemetry = useCallback(async () => {
           try {
             const data = await invoke<SystemSnapshot>('get_system_telemetry');
             setTelemetry(data);
             setError(null);
           } catch (e) {
             setError(String(e));
           } finally {
             setLoading(false);
           }
         }, []);

         useEffect(() => {
           fetchTelemetry();
           const interval = setInterval(fetchTelemetry, pollInterval);
           return () => clearInterval(interval);
         }, [fetchTelemetry, pollInterval]);

         return { telemetry, error, loading, refresh: fetchTelemetry };
       }
       ```

    3. Create `src/hooks/` directory if it doesn't exist.

    4. Test by temporarily adding to Dashboard.tsx:
       ```typescript
       const { telemetry, loading, error } = useTelemetry();
       console.log('Telemetry:', telemetry);
       ```
  </action>
  <verify>
    - TypeScript compiles without errors
    - Hook can be imported in components
    - `npm run tauri dev` shows telemetry in console (when wired up)
  </verify>
  <done>Frontend types and hook ready for telemetry consumption</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Tauri sidecar/subprocess configured for Python
- [ ] Rust command `get_system_telemetry` implemented
- [ ] TypeScript types match Python/Rust types
- [ ] useTelemetry hook polls and returns data
- [ ] `npm run tauri dev` runs without crashes
</verification>

<success_criteria>
- All tasks completed
- Tauri can spawn Python and get telemetry
- Frontend can invoke Tauri command and receive typed data
- Ready for UI implementation in Plan 02-03
</success_criteria>

<output>
After completion, create `.planning/phases/02-hardware-telemetry/02-02-SUMMARY.md`
</output>
