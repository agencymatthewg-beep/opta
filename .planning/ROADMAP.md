# Roadmap: aicomp.Optamized.biz

## Overview

Build a comprehensive AI intelligence hub from the ground up: establish the project foundation with Opta's distinctive visual identity, create robust data pipelines to scrape benchmark sources and provider announcements, store and serve that data through clean APIs, build an interactive dashboard for model comparison and visualization, layer on AI-powered analysis for recommendations and trends, add conversational chat for natural queries, and polish for launch.

## Domain Expertise

None (no domain skill packages available)

## Phases

**Phase Numbering:**
- Integer phases (1, 2, 3): Planned milestone work
- Decimal phases (2.1, 2.2): Urgent insertions (marked with INSERTED)

- [ ] **Phase 1: Foundation** - Next.js project setup with Opta design system and layout structure
- [ ] **Phase 2: Data Pipeline** - Web scraping infrastructure for AI benchmarks and announcements
- [ ] **Phase 3: Data Storage** - Database schema, data models, and API routes
- [ ] **Phase 4: Dashboard Core** - Model comparison views and benchmark visualizations
- [ ] **Phase 5: AI Analysis** - Recommendation engine and trend analysis
- [ ] **Phase 6: Interactive Chat** - Chat interface with data-grounded responses
- [ ] **Phase 7: Polish & Launch** - Final refinements and Vercel deployment

## Phase Details

### Phase 1: Foundation
**Goal**: Establish Next.js project with Opta hybrid design system (Life Manager layout + MacOS visual flair), core layout components, and navigation structure
**Depends on**: Nothing (first phase)
**Research**: Unlikely (familiar Next.js patterns from opta-life-manager)
**Plans**: TBD

Plans:
- [ ] 01-01: Project scaffolding and configuration
- [ ] 01-02: Design system and core components
- [ ] 01-03: Layout structure and navigation

### Phase 2: Data Pipeline
**Goal**: Build automated scraping system for Chatbot Arena, official benchmarks (MMLU, HumanEval, GPQA), and provider announcements (OpenAI, Anthropic, Google blogs)
**Depends on**: Phase 1
**Research**: Likely (web scraping patterns, external data sources)
**Research topics**: Scraping libraries (Cheerio, Puppeteer), rate limiting strategies, data format normalization, cron/scheduling approaches
**Plans**: TBD

Plans:
- [ ] 02-01: Scraping infrastructure and scheduler
- [ ] 02-02: Benchmark source scrapers (Chatbot Arena, official evals)
- [ ] 02-03: Provider announcement scrapers

### Phase 3: Data Storage
**Goal**: Design database schema for models, benchmarks, pricing, and news; create data models and API routes for frontend consumption
**Depends on**: Phase 2
**Research**: Unlikely (standard database patterns)
**Plans**: TBD

Plans:
- [ ] 03-01: Database schema and setup
- [ ] 03-02: API routes for model data
- [ ] 03-03: API routes for benchmarks and news

### Phase 4: Dashboard Core
**Goal**: Build the main dashboard with model comparison tables, benchmark charts, pricing comparisons, and news timeline
**Depends on**: Phase 3
**Research**: Unlikely (React visualization with familiar patterns)
**Plans**: TBD

Plans:
- [ ] 04-01: Model comparison dashboard
- [ ] 04-02: Benchmark visualization charts
- [ ] 04-03: Pricing and capabilities views
- [ ] 04-04: News timeline component

### Phase 5: AI Analysis
**Goal**: Implement AI-powered recommendation engine ("For your use case, Model X is best because...") and trend analysis with charts ("Claude improved 15% on coding benchmarks")
**Depends on**: Phase 4
**Research**: Likely (AI APIs for structured analysis)
**Research topics**: Claude/OpenAI APIs for structured output, prompt engineering for recommendations, trend calculation algorithms
**Plans**: TBD

Plans:
- [ ] 05-01: Recommendation engine
- [ ] 05-02: Trend analysis and charts

### Phase 6: Interactive Chat
**Goal**: Build conversational interface where users can ask questions about models and receive data-grounded answers
**Depends on**: Phase 5
**Research**: Likely (conversational AI, RAG patterns)
**Research topics**: RAG implementation patterns, context management, streaming responses, grounding responses in scraped data
**Plans**: TBD

Plans:
- [ ] 06-01: Chat interface and UX
- [ ] 06-02: Data-grounded response generation

### Phase 7: Polish & Launch
**Goal**: Final visual refinements, performance optimization, SEO setup, and Vercel deployment
**Depends on**: Phase 6
**Research**: Unlikely (familiar deployment patterns)
**Plans**: TBD

Plans:
- [ ] 07-01: Visual polish and performance
- [ ] 07-02: SEO and metadata
- [ ] 07-03: Vercel deployment and launch

## Progress

**Execution Order:**
Phases execute in numeric order: 1 → 2 → 3 → 4 → 5 → 6 → 7

| Phase | Plans Complete | Status | Completed |
|-------|----------------|--------|-----------|
| 1. Foundation | 0/3 | Not started | - |
| 2. Data Pipeline | 0/3 | Not started | - |
| 3. Data Storage | 0/3 | Not started | - |
| 4. Dashboard Core | 0/4 | Not started | - |
| 5. AI Analysis | 0/2 | Not started | - |
| 6. Interactive Chat | 0/2 | Not started | - |
| 7. Polish & Launch | 0/3 | Not started | - |
